{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html_parser import BSParser\n",
    "from report import Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Report(\"..\", \"html\", \"data/Report.html\")\n",
    "h = BSParser(\"data/Report.html\",\"URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['opencitations', ' overview']\n",
      "18/11/2019\n",
      "URL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan.heibi/ivanhb.github.io/edu/model/script/html_parser.py:27: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 27 of the file /Users/ivan.heibi/ivanhb.github.io/edu/model/script/html_parser.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  parsed_html = BeautifulSoup(f)\n"
     ]
    }
   ],
   "source": [
    "print(h.get_keywords())\n",
    "print(h.get_date())\n",
    "print(h.get_source())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.add_entry({\"attribute\":{\"date\":\"1\",\"source\":\"2\"},\"relation\":{\"@hasKeyword\":\"3\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = \"2019-11-18 10:21:38 +0000\"[0:10].split(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = l[2]+\"/\"+l[1]+\"/\"+l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the model index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import codecs\n",
    "import os\n",
    "import json\n",
    "\n",
    "class Graphml(object):\n",
    "\n",
    "    OBJECT_PROP_KEY = \"@\"\n",
    "    SUBCLASS_KEY = \"@isSubclassOf\"\n",
    "    DATATYPES = {\n",
    "        \"string\":{\"default\":\"string\"},\n",
    "        \"int\":{\"default\":\"int\"},\n",
    "        \"datetime\":{\"default\":\"datetime\"},\n",
    "        \"url\":{\"default\":\"url\"}\n",
    "    }\n",
    "\n",
    "    def __init__(self, input, is_path = True):\n",
    "        self.nodes = []\n",
    "        self.edges = []\n",
    "\n",
    "        if is_path:\n",
    "            with codecs.open(input, 'r', encoding='utf8') as f:\n",
    "                self.raw = f.read()\n",
    "                self.soup = BeautifulSoup(self.raw, features=\"html.parser\")\n",
    "        else:\n",
    "            self.raw = input\n",
    "            self.soup = BeautifulSoup(input, features=\"html.parser\")\n",
    "\n",
    "    def get_edges(self):\n",
    "        res = []\n",
    "        edges = self.find_all(\"edge\",{})\n",
    "        for e in edges:\n",
    "            bs_e = BeautifulSoup(str(e),features=\"html.parser\")\n",
    "            res.append({\n",
    "                \"id\": bs_e.find(\"edge\")[\"id\"],\n",
    "                \"source\": bs_e.find(\"edge\")[\"source\"],\n",
    "                \"target\": bs_e.find(\"edge\")[\"target\"],\n",
    "                \"value\": bs_e.find(\"y:edgelabel\").contents\n",
    "            })\n",
    "\n",
    "        for i in range(0,len(res)):\n",
    "            str_on_edge = res[i][\"value\"][0].split(\",\")[0]\n",
    "            res[i][\"value\"] = str_on_edge.replace(\"\\n\",\";\")\n",
    "        return res\n",
    "\n",
    "    def get_nodes(self):\n",
    "        res = []\n",
    "        nodes = self.find_all(\"node\",{})\n",
    "        for n in nodes:\n",
    "            bs_n = BeautifulSoup(str(n),features=\"html.parser\")\n",
    "            res.append({\n",
    "                \"id\": bs_n.find(\"node\")[\"id\"],\n",
    "                \"value\": \"\".join(bs_n.find(\"y:nodelabel\").contents)\n",
    "            })\n",
    "        return res\n",
    "\n",
    "    def find_all(self,tag,att):\n",
    "        return self.soup.findAll(tag,att)\n",
    "\n",
    "\n",
    "    def normalize_into_owl_formalism(self):\n",
    "        OWL_GRAPH = {\n",
    "            \"classes\": [],\n",
    "            \"datatypes\": [],\n",
    "            \"data_properties\": [],\n",
    "            \"object_properties\": []\n",
    "        }\n",
    "\n",
    "        self.nodes = self.get_nodes()\n",
    "        self.edges = self.get_edges()\n",
    "\n",
    "        #Classes and Datatypes\n",
    "        for n in self.nodes:\n",
    "            if(n[\"value\"][0].isupper()):\n",
    "                OWL_GRAPH[\"classes\"].append(n)\n",
    "            else:\n",
    "                OWL_GRAPH[\"datatypes\"].append(n)\n",
    "\n",
    "        # Object/Data properties\n",
    "        obj_props = []\n",
    "        data_props = []\n",
    "        for e in self.edges:\n",
    "            edge_type = \"dataProp\"\n",
    "            if(e[\"value\"][0] == self.OBJECT_PROP_KEY):\n",
    "                edge_type = \"objProp\"\n",
    "\n",
    "            e[\"value\"] = e[\"value\"].split(\";\")\n",
    "            if edge_type == \"dataProp\":\n",
    "                OWL_GRAPH[\"data_properties\"].append(e)\n",
    "            elif edge_type == \"objProp\":\n",
    "                OWL_GRAPH[\"object_properties\"].append(e)\n",
    "\n",
    "        return OWL_GRAPH\n",
    "\n",
    "\n",
    "    # JSON Jago index,\n",
    "    def build_jago_index(self,owl_gr, path = None):\n",
    "\n",
    "        def _find_elem(items_list,att,val):\n",
    "            for item in items_list:\n",
    "                if item[att] == val:\n",
    "                    return item\n",
    "            return -1\n",
    "\n",
    "        def _build_tree(classes_index, class_val, tree):\n",
    "            if self.SUBCLASS_KEY in classes_index[class_val][\"object_properties\"]:\n",
    "                sub_class_val = classes_index[class_val][\"object_properties\"][self.SUBCLASS_KEY]\n",
    "                tree.append(sub_class_val)\n",
    "                return _build_tree(classes_index, sub_class_val, tree)\n",
    "            else:\n",
    "                return tree\n",
    "\n",
    "\n",
    "        index_prefixes = {}\n",
    "        classes_index = {}\n",
    "        for c in owl_gr[\"classes\"]:\n",
    "            classes_index[c[\"value\"]]= {\n",
    "                \"prefix\":None,\n",
    "                \"last_id\": 0,\n",
    "                \"data_properties\": {},\n",
    "                \"object_properties\": {}\n",
    "            }\n",
    "            #check data properties\n",
    "            for dp in owl_gr[\"data_properties\"]:\n",
    "                    if (dp[\"source\"] == c[\"id\"]):\n",
    "                        for dp_val in dp[\"value\"]:\n",
    "                            default_value = -1\n",
    "                            \n",
    "                            target_dp_node = _find_elem(owl_gr[\"datatypes\"],\"id\",dp[\"target\"])\n",
    "                            if target_dp_node != -1:\n",
    "                                if target_dp_node[\"value\"] in self.DATATYPES:\n",
    "                                    default_value = self.DATATYPES[target_dp_node[\"value\"]][\"default\"]\n",
    "                            classes_index[c[\"value\"]][\"data_properties\"][dp_val] = default_value\n",
    "\n",
    "            #check object properties\n",
    "            for op in owl_gr[\"object_properties\"]:\n",
    "                    if (op[\"source\"] == c[\"id\"]):\n",
    "                        for op_val in op[\"value\"]:\n",
    "                            target_node = _find_elem(owl_gr[\"classes\"],\"id\",op[\"target\"])\n",
    "                            classes_index[c[\"value\"]][\"object_properties\"][op_val] = target_node[\"value\"]\n",
    "\n",
    "            #define prefix\n",
    "            pref = c[\"value\"][:2].lower()\n",
    "            i = 2\n",
    "            while (pref in index_prefixes):\n",
    "                pref = pref+c[\"value\"][i].lower()\n",
    "                i += 1\n",
    "            index_prefixes[pref] = True\n",
    "            classes_index[c[\"value\"]][\"prefix\"] = pref\n",
    "\n",
    "        #in case a path where to build the structure is specified\n",
    "        if path != None:\n",
    "            #a local dir\n",
    "            if not path.startswith(\"http\"):\n",
    "                model_path = path+\"model/\"\n",
    "                if not os.path.exists(os.path.dirname(model_path)):\n",
    "                    os.makedirs(model_path)\n",
    "\n",
    "                #save the index.json\n",
    "                with open(model_path+'index.json', 'w') as f:\n",
    "                    data = {\"class\": classes_index}\n",
    "                    json.dump(data, f)\n",
    "\n",
    "                #now all the structure\n",
    "                src_path = path+\"model/src\"\n",
    "                for class_k in classes_index:\n",
    "                    tree = _build_tree(classes_index, class_k, [class_k])\n",
    "                    i = len(tree) - 1\n",
    "                    new_path = \"\";\n",
    "                    while i >= 1:\n",
    "                        new_path = new_path + \"/\"+tree[i].lower()\n",
    "                        i -= 1\n",
    "                    new_path = src_path+new_path+\"/\"+ tree[0].lower()+\".json\"\n",
    "\n",
    "                    #create dirs and file\n",
    "                    if not os.path.exists(os.path.dirname(new_path)):\n",
    "                        os.makedirs(os.path.dirname(new_path))\n",
    "\n",
    "                    with open(new_path, 'w') as f_src:\n",
    "                        json.dump({\"class\":tree[0],\"items\":[]}, f_src)\n",
    "\n",
    "        return classes_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphml = Graphml(\"data/modelv2.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl_gr = graphml.normalize_into_owl_formalism();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATATYPES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f5539cf1aaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraphml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_jago_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mowl_gr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-584ecfa7318b>\u001b[0m in \u001b[0;36mbuild_jago_index\u001b[0;34m(self, owl_gr, path)\u001b[0m\n\u001b[1;32m    130\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mtarget_dp_node\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mtarget_dp_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATATYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                                     \u001b[0mdefault_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATATYPES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_dp_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                             \u001b[0mclasses_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_properties\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdp_val\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATATYPES' is not defined"
     ]
    }
   ],
   "source": [
    "graphml.build_jago_index(owl_gr,\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "class Jago(object):\n",
    "    \n",
    "    model_index = {}\n",
    "    class_index = {}\n",
    "\n",
    "    def __init__(self, jago_model_path): \n",
    "        try:\n",
    "            #the model index first\n",
    "            with open(jago_model_path+\"/\"+\"index.json\") as json_file:\n",
    "                self.model_index = json.load(json_file)  \n",
    "            \n",
    "            #a map to all json files\n",
    "            for root, dirs, files in os.walk(jago_model_path+\"/src\"):\n",
    "                for file in files:\n",
    "                    if file.endswith(\".json\"):\n",
    "                        self.class_index[file.split(\".json\")[0].capitalize()] = os.path.join(root, file) \n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def add_item(self, class_name, data_properties, object_properties):\n",
    "        class_file = None\n",
    "        with open(self.class_index[class_name]) as json_file:\n",
    "            class_file = json.load(json_file) \n",
    "                \n",
    "            id_set = set(list(range(1, len(class_file[\"items\"]) +1))) \n",
    "            for item in class_file[\"items\"]:\n",
    "                if int(item[\"id\"]) in id_set:\n",
    "                    id_set.remove(int(item[\"id\"]))\n",
    "                \n",
    "            an_id = None\n",
    "            for aval_id in id_set:\n",
    "                an_id = str(aval_id)\n",
    "                break\n",
    "            if an_id == None:\n",
    "                an_id = str(len(class_file[\"items\"])+1)\n",
    "                    \n",
    "            class_file[\"items\"].append({\n",
    "                    \"id\": str(an_id),\n",
    "                    \"data_properties\": data_properties,\n",
    "                    \"object_properties\": object_properties\n",
    "            })\n",
    "                \n",
    "        if class_file != None:\n",
    "            with open(self.class_index[class_name], 'w') as f_src:\n",
    "                json.dump(class_file, f_src)\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "jago = Jago(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_item_dataprop = {\"persistentId\": \"PROVA_pid\", \"source\": \"PROVA_source\", \"title\": \"PROVA_title\", \"persistentIdType\": \"PROVA_pidtype\", \"duration\": \"PROVA_duration\", \"date\": \"PROVA_date\"}\n",
    "ex_item_objprop = {\"@hasKeyword\": \"1\"}\n",
    "\n",
    "jago.add_item(\"Demo\", ex_item_dataprop, ex_item_objprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
